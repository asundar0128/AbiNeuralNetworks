{
  "metadata": {
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    },
    "kernelspec": {
      "name": "python",
      "display_name": "Pyolite",
      "language": "python"
    }
  },
  "nbformat_minor": 4,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": "\n#Back Propagate Error\n#Transfer Derivative with Sigmoid Activation Function\ndef transferDerivative_NeuralNetwork(outputGenerated):\n    return (outputGenerated * 1.0 - outputGenerated)\n\n#Error Backpropagation\ndef backwardPropagateError_NeuralNetwork(outputGenerated, expectedValue):\n    for a in reversed(len(neuralNetwork)):\n                      activationLayer = neuralNetwork[i]\n                      errors = list()\n                      if a!= len(neuralNetwork) - 1:\n                          for b in range(len(activationLayer)):\n                            error = 0.0\n                        for neuron in neuralNetwork[a+1]:\n                                error += (neuron['weights'][b] * neuron['delta'])\n                                errors.append(error)\nerror = (outputGenerated - expectedValue) * transferDerivative_NeuralNetwork(outputGenerated)\n\n                      else:\n                          for b in range(len(activationLayer):\n                            neuron = activationLayer[b]\n                            errors.append(neuron['output'] - expectedValue[b]\n                          for b in range(len(activationLayer):\n                            neuron = activationLayer[b]\n                            neuron['delta'] = errors[b] * transferDerivative_NeuralNetwork(neuron['output'])\n\n# test backpropagation of error\nnetwork = [[{'output': 0.7105668883115941, 'weights': [0.13436424411240122, 0.8474337369372327, 0.763774618976614]}],\n           [{'output': 0.6213859615555266, 'weights': [0.2550690257394217, 0.49543508709194095]}, {'output': 0.6573693455986976, 'weights': [0.4494910647887381, 0.651592972722763]}]]\nexpectedValue = [0, 1]\nbackwardPropagateError_NeuralNetwork(neuralNetwork, expectedValue)\nfor activationLayer in neuralNetwork:\n    print(activationLayer)\n",
      "metadata": {
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    }
  ]
}